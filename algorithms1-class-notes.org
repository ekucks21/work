#+STARTUP entitiespretty

* Prerequisites
- math
  - discrete math
  - proofs by induction
  - Mathematics for Computer Science by Eric Lehman and Tom Layden
- programming
* Merge Sort
- example of divide and conquer
  - break problem into smaller problems then combine the smaller solutions 
* Big Oh
** Omega Notation
- T(n)=Omega(f(n)) if and only if there exists constants C,n0 such that T(n) >= C*f(n) for all n >= n0
** Little-oh Notation
- strictly less than vs big oh which is equal to or less than
** Examples
*** Claim: 2^n+10 = O(2^n)
- Proof: need to pick constants such that
  - (*) 2^n+10 <= c*2^n for all n >= n_0
  - Note: 2^n+10 = 2^10 * 2^n = 1024 * 2^n
  - so if we choose c=1024, n_0=1, then (*) holds
* Divide and Conquer Algorithms 
** Steps
- DIVIDE into smaller problems
- CONQUER via recursive calls
- COMBINE solutions of subproblems into one solution
** An example problem
*** Overview
- Input: array A containing the numbers 1,2,3,... in some arbitrary order
- Output: number of inversions. In other words, number of pairs (i, j) of array indices with i < j and A[i] > A[j].
*** Example 1
- (1, 3, 5, 2, 4, 6)
- Inversions: (3,2), (5,2), (5,4)
- Motivation: numerical similarity measure between two ranked lists (e.g. for "collaborative filtering" - propose other things to buy based on other
people with similar purchasing history)
*** solutions
**** brute force: double for loop O(n^2)
**** divide and conquer
- high level
  Count(array A, length n)
    if n=1 return 0
    else
      x=Count(1st half of A, n/2)
      y=Count(2nd half of A, n/2)
      z=CountSplitInv(A,n)
    return x+y+z
- implementation
  - key idea: have recursive calls both count inversions *and* sort (i.e. piggyback on mergesort)
  - motivation: merge subroutine naturally uncovers split inversions
  - example
    - merging [1,3,5] and [2,4,6]
    - when 2 copied to output, discover the split inversions (3,2) and (5,2)
    - when 4 copied to outpu, discover the split inversion (5,4)
  - claim: the split inversions involving an element y of the 2nd array C are precisely the numbers left in the 1st array B when y is copied to the output D
- solution:
  - claim: the split inversions involving and element y in the second array C are precisely the numbers left in the first array B when y is copied to the output D
  - proof:
    - let x be an element of the array B
    - if x is copied to output D before y, then x < y => no inversion involving x and y
    - if y is copied to output D before x, then y < x => x and y are a split inversion
* Strassen's Subcubic Matrix Multiplication Algorithm 
** Matrix Multiplication
*** Definition
- x[][] * y[][] = z[][]
- z_ij = (ith row of x) * (jth column of y) = sum of k=1 to n x_ik * y_jk
*** Example
| a | b | * | e | f | = | ae + bg | af + bh |
| c | d |   | g | h |   | ce + dg | cf + dh |
*** Applying Divide and Conquer
- Idea: 
  write x =
  | a | b |
  | c | d |
  and y =
  | e | f |
  | g | h |
[where A through H are all n/2 * n/2 matrices]
- Then: 
x*y = 
| ae + bg | af + bh |
| ce + dg | cf + dh |
*** Recursive Algorithm #1
- recursively compute the 8 necessary products
- do the necessary additions (O(n^2) time)
- *Fact: runtime is O(n^3)*
*** Strassen's Algorithm (1969)
- recursively compute only 7 (cleverly chosen) products
- do the necessary (clever) additions and subtractions (still O(n^2) time)
- *Fact: better than cubic time!*
**** The Details
- the seven products
  - P1=A(F-H)
  - P2=(A+B)H
  - P3=(C+D)E
  - P4=D(G-E)
  - P5=(A+D)(E+H)
  - P6=(B-D)(G+H)
  - P7=(A-C)(E+F)
- *claim*: x*y=
| p5+p4-p2+p6 | p1+p2       |
|-------------+-------------|
| p3+p4       | p1+p5-p3-p7 |
**** How could you figure this out?
[[http://softwareengineering.stackexchange.com/questions/199627/how-did-strassen-come-up-with-his-matrix-multiplication-method][how did strassen come up with his matrix multiplication method]]
* Algorithm for Closest Pair 
** Problem
- Input: a set p = {p_1,...,p_n} of n points in the plane (R2)
- Notation: d(p_i, p_j) = Euclidean distance
  So if p_i=(x_i, y_i) and p_j=(x_j,y_j), d(p_i, p_j) = square root of (x_i -
  y_i)^2 + (x_j - y_j)^2
- Output: a pair p*, q* in the set p of distinct points that minimi
- Assumption: all points have distinct x-coordinates, distinct y-coordinates
- Brute force search: takes Theta(n^2) time
- 1-dimension version of closest pair: all points lie on a line
  - sort points (O(n log n) time)
  - return closest pair of adjacent points (O(n) time)
- Goal: O(n log n) time algorithm for 2-D version
*** High level approach
    - make copies of points sorted by x-coordinate (Px) and by y-coordinate (Py)
      - sorting is sort of a "for free" data transformation in algorithms
    - use divide and conquer
*** ClosestPair(Px, Py)
    - let Q = left half of P, R = right half of P
      - base case, once you have only 2 or 3 points, brute search for closest points
      - form Qx, Qy, Rx, Ry (takes O(n) time)
    - (p_1, q_1) = ClosestPair(


