#+STARTUP entitiespretty

* Prerequisites
- math
  - discrete math
  - proofs by induction
  - Mathematics for Computer Science by Eric Lehman and Tom Layden
- programming
* Merge Sort
- example of divide and conquer
  - break problem into smaller problems then combine the smaller solutions
- takes 6nlog2n + 6n time
- proof
  - recursion tree
* Guiding Principles for Analysis of Algorithms
- *guiding principle #1: types of analysis*
  - worst case analysis
    - appropriate for general purpose routines
    - easier to analyze
  - average case analysis
    - have to have domain knowledge
  - benchmarks
    - have to have domain knowledge
- *guiding principle #2: don't pay much attention to constant factors, lower order terms*
  - way easier
  - constants depend on architecture/compiler/programmer
  - lose very little predictive power
- *guiding principle #3: asymptotic analysis - focus on running time for large input*
  - for large n, constants matter less and logarithmic vs quadratic matters much
    more (log2n vs n2)
  - only big problems are interesting
  - fast algorithm approximately is where the worst-case running time grows
    slowly with input size
    - *holy grail*: linear running time or close to it
* Asymptotic analysis
- vocabulary for the design and analysis of algorithms (e.g. big-oh notation)
- coarse enough to suppress architecture/language/compiler-dependent details
- sharp enough to make useful comparisons between different algorithms,
  especially on large inputs
- *high-level idea*: suppress constant factors and lower-order terms
- for merge sort, "6nlog_2n + 6n" becomes "n log n"
- running time is O(nlogn)
- examples
  - iterating through an array is O(n)
  - iterating through two arrays of length n is O(n)
  - two nested loops is O(n^2)
  - n^2:
    for i=1 to n
      for j=i+1 to n
        if A[i] == A[j] return true
- T(n) = O(f(n))
  - if eventually (for all sufficiently large n), T(n) is bounded above by a
    constant multiple of f(n)
  - formal definition: T(n) = O(f(n)) if and only if there exist constants c,n_o
    > 0 such that T(n) <= c*f(n) for all n >= n_o
  - claim: if T(n) = a_k*n^k + ... + a_1n + a_o then T(n) = O(n^k)
  - proof: choose n_o=1 and c
